{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports the pandas libray for usage\n",
    "import pandas as pd\n",
    "\n",
    "file_location = \"C:\\\\Users\\\\Maggie\\\\Downloads\\\\maggie_data_v7_collapsed domains.xlsx\"\n",
    "\n",
    "# Read the tsv/txt file\n",
    "tests_df = pd.read_excel(file_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tests_df[['state','year','grade','domain','standard','pvalue','hasPic','questionStem','a','b','c','d','e','completeq']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "acedemic_poly_lemma = set([\n",
    "    'study',\n",
    "    'group',\n",
    "    'system',\n",
    "    'social',\n",
    "    'provide',\n",
    "    'however',\n",
    "    'level',\n",
    "    'result',\n",
    "    'include',\n",
    "    'important',\n",
    "    'process',\n",
    "    'development',\n",
    "    'information',\n",
    "    'effect',\n",
    "    'change',\n",
    "    'table',\n",
    "    'model',\n",
    "    'experience',\n",
    "    'activity',\n",
    "    'human',\n",
    "    'history',\n",
    "    'develop',\n",
    "    'suggest',\n",
    "    'economic',\n",
    "    'low',\n",
    "    'relationship',\n",
    "    'value',\n",
    "    'require',\n",
    "    'role',\n",
    "    'difference',\n",
    "    'analysis',\n",
    "    'practice',\n",
    "    'society',\n",
    "    'thus',\n",
    "    'control',\n",
    "    'form',\n",
    "    'report',\n",
    "    'rate',\n",
    "    'significant',\n",
    "    'figure',\n",
    "    'factor',\n",
    "    'interest',\n",
    "    'culture',\n",
    "    'population',\n",
    "    'type',\n",
    "    'describe',\n",
    "    'indicate',\n",
    "    'image',\n",
    "    'subject',\n",
    "    'science',\n",
    "    'material',\n",
    "    'produce',\n",
    "    'condition',\n",
    "    'identify',\n",
    "    'support',\n",
    "    'performance',\n",
    "    'project',\n",
    "    'approach',\n",
    "    'support',\n",
    "    'period',\n",
    "    'organization',\n",
    "    'environmental',\n",
    "    'source',\n",
    "    'nature',\n",
    "    'cultural',\n",
    "    'resource',\n",
    "    'century',\n",
    "    'strategy',\n",
    "    'theory',\n",
    "    'product',\n",
    "    'goal',\n",
    "    'likely',\n",
    "    'note',\n",
    "    'represent',\n",
    "    'general',\n",
    "    'article',\n",
    "    'environment',\n",
    "    'language',\n",
    "    'determine',\n",
    "    'structure',\n",
    "    'section',\n",
    "    'common',\n",
    "    'occur',\n",
    "    'available',\n",
    "    'term',\n",
    "    'reduce',\n",
    "    'measure',\n",
    "    'involve',\n",
    "    'movement',\n",
    "    'specific',\n",
    "    'focus',\n",
    "    'region',\n",
    "    'relate',\n",
    "    'individual',\n",
    "    'quality',\n",
    "    'establish',\n",
    "    'author',\n",
    "    'seek',\n",
    "    'compare',\n",
    "    'growth',\n",
    "    'natural',\n",
    "    'various',\n",
    "    'standard',\n",
    "    'example',\n",
    "    'management',\n",
    "    'argue',\n",
    "    'degree',\n",
    "    'design',\n",
    "    'concern',\n",
    "    'examine',\n",
    "    'pattern',\n",
    "    'traditional',\n",
    "    'finding',\n",
    "    'positive',\n",
    "    'central',\n",
    "    'act',\n",
    "    'impact',\n",
    "    'reflect',\n",
    "    'recognize',\n",
    "    'context',\n",
    "    'relation',\n",
    "    'maintain',\n",
    "    'discussion',\n",
    "    'associate',\n",
    "    'design',\n",
    "    'particularly',\n",
    "    'purpose',\n",
    "    'address',\n",
    "    'particular',\n",
    "    'benefit',\n",
    "    'survey',\n",
    "    'effective',\n",
    "    'apply',\n",
    "    'contain',\n",
    "    'understanding',\n",
    "    'production',\n",
    "    'form',\n",
    "    'association',\n",
    "    'reveal',\n",
    "    'range',\n",
    "    'status',\n",
    "    'necessary',\n",
    "    'function',\n",
    "    'indeed',\n",
    "    'global',\n",
    "    'conflict',\n",
    "    'conduct',\n",
    "    'critical',\n",
    "    'perform',\n",
    "    'discus',\n",
    "    'exist',\n",
    "    'improve',\n",
    "    'observe',\n",
    "    'demonstrate',\n",
    "    'unit',\n",
    "    'total',\n",
    "    'modern',\n",
    "    'literature',\n",
    "    'result',\n",
    "    'experience',\n",
    "    'principle',\n",
    "    'element',\n",
    "    'challenge',\n",
    "    'control',\n",
    "    'historical',\n",
    "    'aspect',\n",
    "    'measure',\n",
    "    'belief',\n",
    "    'western',\n",
    "    'technique',\n",
    "    'generally',\n",
    "    'importance',\n",
    "    'application',\n",
    "    'feature',\n",
    "    'influence',\n",
    "    'basis',\n",
    "    'refer',\n",
    "    'communication',\n",
    "    'negative',\n",
    "    'primary',\n",
    "    'variety',\n",
    "    'following',\n",
    "    'access',\n",
    "    'contribute',\n",
    "    'assume',\n",
    "    'tool',\n",
    "    'promote',\n",
    "    'labor',\n",
    "    'engage',\n",
    "    'review',\n",
    "    'highly',\n",
    "    'publish',\n",
    "    'encourage',\n",
    "    'ass',\n",
    "    'view',\n",
    "    'instrument',\n",
    "    'meaning',\n",
    "    'limit',\n",
    "    'directly',\n",
    "    'previous',\n",
    "    'demand',\n",
    "    'vision',\n",
    "    'female',\n",
    "    'attempt',\n",
    "    'influence',\n",
    "    'independent',\n",
    "    'solution',\n",
    "    'direct',\n",
    "    'conclusion',\n",
    "    'presence',\n",
    "    'scientific',\n",
    "    'ethnic',\n",
    "    'active',\n",
    "    'male',\n",
    "    'claim',\n",
    "    'focus',\n",
    "    'contrast',\n",
    "    'failure',\n",
    "    'internal',\n",
    "    'journal',\n",
    "    'facility',\n",
    "    'emerge',\n",
    "    'protection',\n",
    "    'extent',\n",
    "    'male',\n",
    "    'mental',\n",
    "    'explore',\n",
    "    'generate',\n",
    "    'requirement',\n",
    "    'broad',\n",
    "    'observation',\n",
    "    'difficulty',\n",
    "    'perceive',\n",
    "    'female',\n",
    "    'capacity',\n",
    "    'extend',\n",
    "    'connection',\n",
    "    'sector',\n",
    "    'commitment',\n",
    "    'interpretation',\n",
    "    'conclude',\n",
    "    'notion',\n",
    "    'domestic',\n",
    "    'consist',\n",
    "    'reference',\n",
    "    'adopt',\n",
    "    'comparison',\n",
    "    'depend',\n",
    "    'standard',\n",
    "    'employ',\n",
    "    'definition',\n",
    "    'essential',\n",
    "    'contact',\n",
    "    'actual',\n",
    "    'dimension',\n",
    "    'theme',\n",
    "    'largely',\n",
    "    'link',\n",
    "    'desire',\n",
    "    'consistent',\n",
    "    'distribution',\n",
    "    'minority',\n",
    "    'analyze',\n",
    "    'psychological',\n",
    "    'unique',\n",
    "    'experiment',\n",
    "    'trend',\n",
    "    'exchange',\n",
    "    'implication',\n",
    "    'contribution',\n",
    "    'organize',\n",
    "    'emotional',\n",
    "    'locate',\n",
    "    'improvement',\n",
    "    'rural',\n",
    "    'core',\n",
    "    'volume',\n",
    "    'limited',\n",
    "    'propose',\n",
    "    'framework',\n",
    "    'creation',\n",
    "    'code',\n",
    "    'emphasis',\n",
    "    'industrial',\n",
    "    'external',\n",
    "    'waste',\n",
    "    'potential',\n",
    "    'climate',\n",
    "    'explanation',\n",
    "    'technical',\n",
    "    'mechanism',\n",
    "    'description',\n",
    "    'vary',\n",
    "    'reduction',\n",
    "    'discipline',\n",
    "    'construct',\n",
    "    'equal',\n",
    "    'origin',\n",
    "    'fundamental',\n",
    "    'existence',\n",
    "    'formal',\n",
    "    'manner',\n",
    "    'assistance',\n",
    "    'planning',\n",
    "    'cite',\n",
    "    'judgment',\n",
    "    'constitute',\n",
    "    'typical',\n",
    "    'selection',\n",
    "    'incorporate',\n",
    "    'illustrate',\n",
    "    'cycle',\n",
    "    'depression',\n",
    "    'consideration',\n",
    "    'arise',\n",
    "    'separate',\n",
    "    'recognition',\n",
    "    'mode',\n",
    "    'resistance',\n",
    "    'diversity',\n",
    "    'practical',\n",
    "    'acquire',\n",
    "    'characterize',\n",
    "    'differ',\n",
    "    'review',\n",
    "    'interpret',\n",
    "    'creative',\n",
    "    'limitation',\n",
    "    'resolution',\n",
    "    'revolution',\n",
    "    'philosophy',\n",
    "    'display',\n",
    "    'publication',\n",
    "    'variation',\n",
    "    'derive',\n",
    "    'permit',\n",
    "    'alternative',\n",
    "    'initiative',\n",
    "    'employment',\n",
    "    'regard',\n",
    "    'estimate',\n",
    "    'transform',\n",
    "    'absence',\n",
    "    'imply',\n",
    "    'observer',\n",
    "    'link',\n",
    "    'evolution',\n",
    "    'signal',\n",
    "    'biological',\n",
    "    'introduction',\n",
    "    'boundary',\n",
    "    'theoretical',\n",
    "    'settlement',\n",
    "    'independence',\n",
    "    'yield',\n",
    "    'formation',\n",
    "    'insight',\n",
    "    'territory',\n",
    "    'conventional',\n",
    "    'inform',\n",
    "    'index',\n",
    "    'distinction',\n",
    "    'relative',\n",
    "    'identification',\n",
    "    'monitor',\n",
    "    'domain',\n",
    "    'strategic',\n",
    "    'preference',\n",
    "    'profession',\n",
    "    'apparent',\n",
    "    'assign',\n",
    "    'dependent',\n",
    "    'presentation',\n",
    "    'proportion',\n",
    "    'universal',\n",
    "    'norm',\n",
    "    'tendency',\n",
    "    'equally',\n",
    "    'resolve',\n",
    "    'competitive',\n",
    "    'related',\n",
    "    'symbol',\n",
    "    'consumption',\n",
    "    'calculate',\n",
    "    'extensive',\n",
    "    'barrier',\n",
    "    'advanced',\n",
    "    'adjustment',\n",
    "    'shape',\n",
    "    'integrate',\n",
    "    'dominate',\n",
    "    'establishment',\n",
    "    'entry',\n",
    "    'visible',\n",
    "    'sequence',\n",
    "    'hence',\n",
    "    'dialogue',\n",
    "    'distinct',\n",
    "    'enterprise',\n",
    "    'scope',\n",
    "    'assert',\n",
    "    'capability',\n",
    "    'reflection',\n",
    "    'precisely',\n",
    "    'electronic',\n",
    "    'distinguish',\n",
    "    'evolve',\n",
    "    'survival',\n",
    "    'recommendation',\n",
    "    'encounter',\n",
    "    'membership',\n",
    "    'adapt',\n",
    "    'rapid',\n",
    "    'collective',\n",
    "    'reinforce',\n",
    "    'ethical',\n",
    "    'exhibit',\n",
    "    'function',\n",
    "    'communicate',\n",
    "    'valuable',\n",
    "    'wealth',\n",
    "    'initiate',\n",
    "    'ideal',\n",
    "    'indicator',\n",
    "    'strengthen',\n",
    "    'accurate',\n",
    "    'assembly',\n",
    "    'acceptance',\n",
    "    'stress',\n",
    "    'stable',\n",
    "    'guideline',\n",
    "    'justify',\n",
    "    'profile',\n",
    "    'attribute',\n",
    "    'exclude',\n",
    "    'advance',\n",
    "    'sustain',\n",
    "    'mutual',\n",
    "    'radical',\n",
    "    'virtue',\n",
    "    'equation',\n",
    "    'evident',\n",
    "    'highlight',\n",
    "    'input',\n",
    "    'functional',\n",
    "    'distribute',\n",
    "    'scheme',\n",
    "    'ethic',\n",
    "    'exceed',\n",
    "    'format',\n",
    "    'convert',\n",
    "    'innovation',\n",
    "    'obligation',\n",
    "    'inquiry',\n",
    "    'output',\n",
    "    'extension',\n",
    "    'guide',\n",
    "    'prominent',\n",
    "    'logic',\n",
    "    'maintenance',\n",
    "    'constraint',\n",
    "    'dynamic',\n",
    "    'circuit',\n",
    "    'ritual',\n",
    "    'workshop',\n",
    "    'discrimination',\n",
    "    'restriction',\n",
    "    'compose',\n",
    "    'autonomy',\n",
    "    'aim',\n",
    "    'accuracy',\n",
    "    'acceptable',\n",
    "    'restrict',\n",
    "    'conception',\n",
    "    'province',\n",
    "    'minimize',\n",
    "    'spectrum',\n",
    "    'realm',\n",
    "    'absolute',\n",
    "    'array',\n",
    "    'separation',\n",
    "    'concern',\n",
    "    'abstract',\n",
    "    'foster',\n",
    "    'continuous',\n",
    "    'colony',\n",
    "    'undermine',\n",
    "    'superior',\n",
    "    'civilization',\n",
    "    'transmission',\n",
    "    'inventory',\n",
    "    'occupation',\n",
    "    'underlying',\n",
    "    'encounter',\n",
    "    'readily',\n",
    "    'quantity',\n",
    "    'reliable',\n",
    "    'probability',\n",
    "    'informal',\n",
    "    'aggression',\n",
    "    'acquisition',\n",
    "    'similarity',\n",
    "    'govern',\n",
    "    'integrity',\n",
    "    'specify',\n",
    "    'likewise',\n",
    "    'correspond',\n",
    "    'sphere',\n",
    "    'linear',\n",
    "    'model',\n",
    "    'explicit',\n",
    "    'virtual',\n",
    "    'necessity',\n",
    "    'hierarchy',\n",
    "    'obstacle',\n",
    "    'import',\n",
    "    'productive',\n",
    "    'progressive',\n",
    "    'conversion',\n",
    "    'label',\n",
    "    'articulate',\n",
    "    'profound',\n",
    "    'ideal',\n",
    "    'rational',\n",
    "    'value',\n",
    "    'objective',\n",
    "    'sum',\n",
    "    'consistency',\n",
    "    'representative',\n",
    "    'positively',\n",
    "    'survey',\n",
    "    'comparable',\n",
    "    'revolutionary',\n",
    "    'isolate',\n",
    "    'promotion',\n",
    "    'residential',\n",
    "    'adaptation',\n",
    "    'neutral',\n",
    "    'precise',\n",
    "    'flexible',\n",
    "    'conceive',\n",
    "    'persist',\n",
    "    'valid',\n",
    "    'embody',\n",
    "    'stimulate',\n",
    "    'diminish',\n",
    "    'comparative',\n",
    "    'partial',\n",
    "    'fixed',\n",
    "    'matrix',\n",
    "    'innovative',\n",
    "    'voluntary',\n",
    "    'induce',\n",
    "    'outline',\n",
    "    'appreciation',\n",
    "    'favorable',\n",
    "    'morality',\n",
    "    'philosopher',\n",
    "    'manipulate',\n",
    "    'tolerance',\n",
    "    'accordingly',\n",
    "    'logical',\n",
    "    'exploit',\n",
    "    'inadequate',\n",
    "    'desirable',\n",
    "    'dependence',\n",
    "    'reside',\n",
    "    'transport',\n",
    "    'formulate',\n",
    "    'aid',\n",
    "    'frontier',\n",
    "    'accessible',\n",
    "    'exclusion',\n",
    "    'projection',\n",
    "    'stance',\n",
    "    'transmit',\n",
    "    'governance',\n",
    "    'notably',\n",
    "    'configuration',\n",
    "    'center',\n",
    "    'intensive',\n",
    "    'regard',\n",
    "    'attachment',\n",
    "    'indirect',\n",
    "    'interactive',\n",
    "    'invoke',\n",
    "    'differentiate',\n",
    "    'reproduce',\n",
    "    'coordinate',\n",
    "    'revision',\n",
    "    'passive',\n",
    "    'isolated',\n",
    "    'modeling',\n",
    "    'thesis',\n",
    "    'occurrence',\n",
    "    'authentic',\n",
    "    'marginal',\n",
    "    'designate',\n",
    "    'correspondence',\n",
    "    'maximize',\n",
    "    'implicit',\n",
    "    'erosion',\n",
    "    'striking',\n",
    "    'invention',\n",
    "    'fraction',\n",
    "    'disturbance',\n",
    "    'large-scale',\n",
    "    'reconstruction',\n",
    "    'contrast',\n",
    "    'export',\n",
    "    'usage',\n",
    "    'persistent',\n",
    "    'allocation',\n",
    "    'compensate',\n",
    "    'coordination',\n",
    "    'formulation',\n",
    "    'ironically',\n",
    "    'progress',\n",
    "    'operational',\n",
    "    'revise',\n",
    "    'parallel',\n",
    "    'exert',\n",
    "    'absent',\n",
    "    'hostility',\n",
    "    'embed',\n",
    "    'extract',\n",
    "    'suppress',\n",
    "    'disagreement',\n",
    "    'neglect',\n",
    "    'territorial',\n",
    "    'lesser',\n",
    "    'cultivate',\n",
    "    'precede',\n",
    "    'selective',\n",
    "    'pathway',\n",
    "    'autonomous',\n",
    "    'confine',\n",
    "    'fulfill',\n",
    "    'elicit',\n",
    "    'parallel',\n",
    "    'synthesis',\n",
    "    'underscore',\n",
    "    'linkage',\n",
    "    'mobilize',\n",
    "    'viewpoint',\n",
    "    'import',\n",
    "    'provincial',\n",
    "    'collaborate',\n",
    "    'interference',\n",
    "    'verify',\n",
    "    'conform',\n",
    "    'advancement',\n",
    "    'validate',\n",
    "    'coherent',\n",
    "    'intermediate',\n",
    "    'empower',\n",
    "    'compatible',\n",
    "    'monopoly',\n",
    "    'uniform',\n",
    "    'generator',\n",
    "    'generic',\n",
    "    'degradation',\n",
    "    'maternal',\n",
    "    'primitive',\n",
    "    'coincide',\n",
    "    'dependency',\n",
    "    'appropriation',\n",
    "    'refine',\n",
    "    'inconsistent',\n",
    "    'substitute',\n",
    "    'apparatus',\n",
    "    'thorough',\n",
    "    'robust',\n",
    "    'plausible',\n",
    "    'maturity',\n",
    "    'adhere',\n",
    "    'elaborate',\n",
    "    'focal',\n",
    "    'distortion',\n",
    "    'qualification',\n",
    "    'alignment',\n",
    "    'migrate',\n",
    "    'rigorous',\n",
    "    'preclude',\n",
    "    'inferior',\n",
    "    'multiply',\n",
    "    'enlightenment',\n",
    "    'Greek',\n",
    "    'reconcile',\n",
    "    'straightforward',\n",
    "    'privileged',\n",
    "    'complementary',\n",
    "    'susceptible',\n",
    "    'succession',\n",
    "    'decisive',\n",
    "    'spontaneous',\n",
    "    'contention',\n",
    "    'accumulation',\n",
    "    'displace',\n",
    "    'probe',\n",
    "    'broaden',\n",
    "    'reconstruct',\n",
    "    'definitive',\n",
    "    'resonance',\n",
    "    'contradict',\n",
    "    'unstable',\n",
    "    'appendix',\n",
    "    'infer',\n",
    "    'distort',\n",
    "    'manual',\n",
    "    'confer',\n",
    "    'reversal',\n",
    "    'imperative',\n",
    "    'infinite',\n",
    "    'probable',\n",
    "    'consolidate',\n",
    "    'unrelated',\n",
    "    'acknowledgment',\n",
    "    'discriminate',\n",
    "    'denote',\n",
    "    'hinder',\n",
    "    'friction',\n",
    "    'equilibrium',\n",
    "    'mandate',\n",
    "    'erode',\n",
    "    'fusion',\n",
    "    'presently',\n",
    "    'authoritative',\n",
    "    'alteration',\n",
    "    'adult',\n",
    "    'collaborator',\n",
    "    'contour',\n",
    "    'allowance',\n",
    "    'citation',\n",
    "    'disperse',\n",
    "    'unsuccessful',\n",
    "    'transparency',\n",
    "    'inheritance',\n",
    "    'catalyst',\n",
    "    'subordinate',\n",
    "    'conserve',\n",
    "    'facet',\n",
    "    'preoccupation',\n",
    "    'assimilate',\n",
    "    'enlarge',\n",
    "    'delineate',\n",
    "    'estimation',\n",
    "    'portrayal',\n",
    "    'richness',\n",
    "    'bridge',\n",
    "    'individualism',\n",
    "    'experimentation',\n",
    "    'continuation',\n",
    "    'disparate',\n",
    "    'degrade',\n",
    "    'incompatible',\n",
    "    'nominal',\n",
    "    'substitution',\n",
    "    'novelty',\n",
    "    'containment',\n",
    "    'directory',\n",
    "    'restricted',\n",
    "    'synthesize',\n",
    "    'customary',\n",
    "    'emanate',\n",
    "    'breadth',\n",
    "    'unequal',\n",
    "    'multitude',\n",
    "    'irregular',\n",
    "    'conformity',\n",
    "    'inconsistency',\n",
    "    'sharing',\n",
    "    'continual',\n",
    "    'capitalist',\n",
    "    'amplify',\n",
    "    'outweigh',\n",
    "    'intellect',\n",
    "    'speculative',\n",
    "    'persuasion',\n",
    "    'abandonment',\n",
    "    'endow',\n",
    "    'intrusion',\n",
    "    'two-way',\n",
    "    'measurable',\n",
    "    'underline',\n",
    "    'refinement',\n",
    "    'geometric',\n",
    "    'inadequacy',\n",
    "    'lecturer',\n",
    "    'completed',\n",
    "    'permeate',\n",
    "    'dissolution',\n",
    "    'receptive',\n",
    "    'omission',\n",
    "    'further',\n",
    "    'impart',\n",
    "    'impediment',\n",
    "    'endemic',\n",
    "    'concentrated',\n",
    "    'suggestive',\n",
    "    'stratum',\n",
    "    'bonding',\n",
    "    'repetitive',\n",
    "    'unfavorable',\n",
    "    'propagate',\n",
    "    'transcription',\n",
    "    'diffuse',\n",
    "    'neutralize',\n",
    "    'refute',\n",
    "    'conditional',\n",
    "    'infancy',\n",
    "    'approximation',\n",
    "    'parochial',\n",
    "    'ordering',\n",
    "    'separated',\n",
    "    'expulsion',\n",
    "    'immersion',\n",
    "    'triad',\n",
    "    'pathological',\n",
    "    'negate',\n",
    "    'conjunction',\n",
    "    'elective',\n",
    "    'retrieval',\n",
    "    'predominate',\n",
    "    'diverge',\n",
    "    'intertwine',\n",
    "    'virtuous',\n",
    "    'enlargement',\n",
    "    'topography',\n",
    "    'impersonal',\n",
    "    'normalize',\n",
    "    'outward',\n",
    "    'overestimate',\n",
    "    'maturation',\n",
    "    'utilitarian',\n",
    "    'colonize',\n",
    "    'approximate',\n",
    "    'increment',\n",
    "    'rudimentary',\n",
    "    'expressed',\n",
    "    'paternal',\n",
    "    'material',\n",
    "    'potency',\n",
    "    'inertia',\n",
    "    'compulsion',\n",
    "    'index',\n",
    "    'repress',\n",
    "    'redundant',\n",
    "    'inaccessible',\n",
    "    'predisposition',\n",
    "    'directional',\n",
    "    'rupture',\n",
    "    'replete',\n",
    "    'devalue',\n",
    "    'auxiliary',\n",
    "    'condense',\n",
    "    'unskilled',\n",
    "    'monolithic',\n",
    "    'hereditary',\n",
    "    'unaffected',\n",
    "    'doubling',\n",
    "    'harmonize',\n",
    "    'inward',\n",
    "    'impractical',\n",
    "    'unrestricted',\n",
    "    'hereafter',\n",
    "    'generality',\n",
    "    'dynamism',\n",
    "    'indefinite',\n",
    "    'prompt',\n",
    "    'collected',\n",
    "    'expert',\n",
    "    'redundancy',\n",
    "    'modulate',\n",
    "    'recast',\n",
    "    'persistently',\n",
    "    'drafting',\n",
    "    'credence',\n",
    "    'shaping',\n",
    "    'predominance',\n",
    "    'crystallize',\n",
    "    'unrecognized',\n",
    "    'regenerate',\n",
    "    'allowable',\n",
    "    'framing',\n",
    "    'partition',\n",
    "    'corrosive',\n",
    "    'dictum',\n",
    "    'directed',\n",
    "    'monopolize',\n",
    "    'peculiarity',\n",
    "    'bottleneck',\n",
    "    'invalid',\n",
    "    'reversible',\n",
    "    'spurious',\n",
    "    'equivocal',\n",
    "    'simplification',\n",
    "    'inflexible',\n",
    "    'innermost',\n",
    "    'supposition',\n",
    "    'distinguishable',\n",
    "    'stricture',\n",
    "    'dissociate',\n",
    "    'malleable',\n",
    "    'dispensation',\n",
    "    'inhospitable',\n",
    "    'disentangle',\n",
    "    'opacity',\n",
    "    'constancy',\n",
    "    'unacknowledged',\n",
    "    'unsound',\n",
    "    'unsupported',\n",
    "    'subservient',\n",
    "    'entangled',\n",
    "    'disposed',\n",
    "    'modelling',\n",
    "    'arguable',\n",
    "    'reversion',\n",
    "    'tangential'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import json\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "COLUMN_WORD_COUNT = \"word_count\"\n",
    "COLUMN_READABILITY_FC = \"readability_flesch_kincaid\"\n",
    "COLUMN_ACEDEMIC_POLYSEMOUS_COUNT = \"acedemic_polysemous_count\"\n",
    "COLUMN_ACEDEMIC_POLYSEMOUS_WORDS = \"acedemic_polysemous_words\"\n",
    "COLUMN_POS_TAGS = \"pos_tags\"\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'[a-zA-Z_-]+')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "penn_tree_symbols = ['CC','CD','DT','EX','FW','IN','JJ','JJR','JJS','LS','MD','NN','NNS','NNP','NNPS','PDT','POS','PRP','PRP$','RB','RBR','RBS','RP', 'SYM','TO','UH','VB','VBD','VBG','VBN','VBP','VBZ', 'VVD', 'VVG', 'VVN', 'WDT','WP','WP$','WRB', '$', ',', ':']\n",
    "math_symbols = ['+', '-', '*', '/', '=' ]\n",
    "\n",
    "class DataTransformer:\n",
    "    def __init__(self, \n",
    "                 question_column_name = 'questionStem', \n",
    "                 answer_a_column_name = 'a', \n",
    "                 answer_b_column_name = 'b', \n",
    "                 answer_c_column_name = 'c', \n",
    "                 answer_d_column_name = 'd', \n",
    "                 answer_e_column_name = 'e',\n",
    "                 leading_space = True):\n",
    "        self.question_column_name = question_column_name\n",
    "        self.answer_a_column_name = answer_a_column_name\n",
    "        self.answer_b_column_name = answer_b_column_name\n",
    "        self.answer_c_column_name = answer_c_column_name\n",
    "        self.answer_d_column_name = answer_d_column_name\n",
    "        self.answer_e_column_name = answer_e_column_name\n",
    "        self.leading_space = leading_space\n",
    "        \n",
    "    # Enhance original data with POS, word count, and readability\n",
    "    def transform(self, df):\n",
    "        # Creates a new copy of the dataframe so it doesn't effect the original one\n",
    "        new_df = df.copy()\n",
    "        new_df = self.__update_columns(new_df)\n",
    "        \n",
    "        new_df = new_df.apply (lambda row: self.__update_row(row), axis=1)\n",
    "        return new_df\n",
    "    \n",
    "    # Define a function that adds each penn treebank symbols to the dataframe and one column for the entire pos tags list\n",
    "    def __update_columns(self, df):\n",
    "        # Loop though each symbol and create a column for it with a default vaslue of 0\n",
    "        for symbol in penn_tree_symbols:\n",
    "            df[symbol] = 0\n",
    "\n",
    "        # Add word count column\n",
    "        df[COLUMN_WORD_COUNT] = 0\n",
    "        df[COLUMN_READABILITY_FC] = 0\n",
    "        df[COLUMN_ACEDEMIC_POLYSEMOUS_COUNT] = 0\n",
    "        df[COLUMN_ACEDEMIC_POLYSEMOUS_WORDS] = ''\n",
    "        df[COLUMN_POS_TAGS] = ''\n",
    "        \n",
    "        # Ensure column is string\n",
    "        df[self.answer_a_column_name] = df[self.answer_a_column_name].apply(str)\n",
    "        df[self.answer_b_column_name] = df[self.answer_b_column_name].apply(str)\n",
    "        df[self.answer_c_column_name] = df[self.answer_c_column_name].apply(str)\n",
    "        df[self.answer_d_column_name] = df[self.answer_d_column_name].apply(str)\n",
    "        df[self.answer_e_column_name] = df[self.answer_e_column_name].apply(str)\n",
    "        \n",
    "        # fill n/a will empty string for questions with no answers\n",
    "        df[self.answer_a_column_name] = df[self.answer_a_column_name].fillna('')\n",
    "        df[self.answer_b_column_name] = df[self.answer_b_column_name].fillna('')\n",
    "        df[self.answer_c_column_name] = df[self.answer_c_column_name].fillna('')\n",
    "        df[self.answer_d_column_name] = df[self.answer_d_column_name].fillna('')\n",
    "        df[self.answer_e_column_name] = df[self.answer_e_column_name].fillna('')\n",
    "        \n",
    "        df = df.apply (lambda row: self.__update_slashes(row), axis=1)\n",
    "        df = df.apply (lambda row: self.__update_na(row), axis=1)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def __update_row(self, row):\n",
    "        text_sets = [\n",
    "            row[self.question_column_name],\n",
    "            row[self.answer_a_column_name],\n",
    "            row[self.answer_b_column_name],\n",
    "            row[self.answer_c_column_name],\n",
    "            row[self.answer_d_column_name],\n",
    "            row[self.answer_e_column_name]\n",
    "        ]\n",
    "        \n",
    "        try:\n",
    "            full_question = ' '.join(text_sets)\n",
    "            full_question_word_tokens = tokenizer.tokenize(full_question)\n",
    "        except:\n",
    "            raise Exception(f'Question and answers must be non-null text. You may have digits in a column instead. {text_sets}')\n",
    "        \n",
    "        self.__update_penn_treebank(row, full_question)\n",
    "        self.__update_word_count(row, full_question_word_tokens)\n",
    "        self.__update_readability(row, text_sets)\n",
    "        self.__update_polysemous_count(row, full_question_word_tokens)\n",
    "        \n",
    "        # Excel is stupid\n",
    "        if self.leading_space:\n",
    "            row[self.question_column_name] = ' ' + row[self.question_column_name]\n",
    "            row[self.answer_a_column_name] = ' ' + row[self.answer_a_column_name]\n",
    "            row[self.answer_b_column_name] = ' ' + row[self.answer_b_column_name]\n",
    "            row[self.answer_c_column_name] = ' ' + row[self.answer_c_column_name]\n",
    "            row[self.answer_d_column_name] = ' ' + row[self.answer_d_column_name]\n",
    "            row[self.answer_e_column_name] = ' ' + row[self.answer_e_column_name]\n",
    "        \n",
    "        return row\n",
    "    \n",
    "    import re\n",
    "\n",
    "    def __update_slashes(self, row):\n",
    "\n",
    "        row[self.question_column_name] = re.sub('(.)(/)(.)', r'\\1 / \\3', row[self.question_column_name])\n",
    "        row[self.answer_a_column_name] = re.sub('(.)(/)(.)', r'\\1 / \\3', row[self.answer_a_column_name])\n",
    "        row[self.answer_b_column_name] = re.sub('(.)(/)(.)', r'\\1 / \\3', row[self.answer_b_column_name])\n",
    "        row[self.answer_c_column_name] = re.sub('(.)(/)(.)', r'\\1 / \\3', row[self.answer_c_column_name])\n",
    "        row[self.answer_d_column_name] = re.sub('(.)(/)(.)', r'\\1 / \\3', row[self.answer_d_column_name])\n",
    "        row[self.answer_e_column_name] = re.sub('(.)(/)(.)', r'\\1 / \\3', row[self.answer_e_column_name])\n",
    "        \n",
    "        return row\n",
    "    \n",
    "    def __update_na(self, row):\n",
    "        if row[self.answer_e_column_name] is None or row[self.answer_e_column_name].strip().lower() == 'na' or row[self.answer_e_column_name].strip().lower() == 'nan':\n",
    "            row[self.answer_e_column_name] = ''\n",
    "        \n",
    "        return row\n",
    "\n",
    "    # Define a function that transforms a row from the dataframe and adds the count of penn treebank symbols found\n",
    "    def __update_penn_treebank(self, row, full_question): \n",
    "        # Tokenize the text from the column text\n",
    "        tokenized = nlp(full_question)\n",
    "        \n",
    "        j_data = []\n",
    "\n",
    "        # Loop through each pos tag\n",
    "        for tag in tokenized:\n",
    "            # Manually change the tag if its a known symbol given the math context\n",
    "            output_tag = tag.tag_\n",
    "            if tag.text in math_symbols:\n",
    "                output_tag = 'SYM'\n",
    "            \n",
    "            j_data.append({'text':tag.text, 'original_tag': tag.tag_, 'output_tag': output_tag})\n",
    "            \n",
    "            # Check if the tag is a penn treebank symbol \n",
    "            # Note: The pos tag is a tuple (token, symbol). So we use index 1 to check the symbol\n",
    "            if output_tag in row:\n",
    "                # Retieve the current row value for the symbol and add 1\n",
    "                row[output_tag] += 1\n",
    "        \n",
    "         # Add POS tag details to column\n",
    "        row[COLUMN_POS_TAGS] = json.dumps(j_data)\n",
    "    \n",
    "    # Use the word only tokenizer then get the count\n",
    "    def __update_word_count(self, row, word_tokens):\n",
    "        row[COLUMN_WORD_COUNT] = len(word_tokens)\n",
    "    \n",
    "    # Calculate a readability score and update the row element\n",
    "    def __update_readability(self, row, text_sets):\n",
    "        # First we use the sentence tokeniszer to futher break each text set into sentences\n",
    "        all_sentences = []\n",
    "        for text in text_sets:\n",
    "            all_sentences.extend(sent_tokenize(text))\n",
    "        \n",
    "        # For each sentence we tokenize only the words in it\n",
    "        all_token_sets = []\n",
    "        for text_set in all_sentences:\n",
    "            word_tokens = tokenizer.tokenize(text_set)\n",
    "            \n",
    "            # If the question contained only numbers then we will not include the blank tokens\n",
    "            if len(word_tokens) > 0:\n",
    "                all_token_sets.append(word_tokens)\n",
    "        \n",
    "        # For each sentence token sets, we will calculate the syllable counts\n",
    "        syl_counts = []\n",
    "        for sentence_token_set in all_token_sets:\n",
    "            syl_counts.extend(self.__syllable_counts(sentence_token_set))\n",
    "            \n",
    "        total_syl_count = 0\n",
    "        total_word_count = 0\n",
    "        \n",
    "        # Calculate total syllable count\n",
    "        for value in syl_counts:\n",
    "            total_syl_count += value['syllables']\n",
    "            \n",
    "        # Calculate total word count\n",
    "        for word_tokens in all_token_sets:\n",
    "            total_word_count += len(word_tokens)\n",
    "            \n",
    "        score = 0\n",
    "        try:\n",
    "            asl = total_word_count / len(all_token_sets)\n",
    "            asw = total_syl_count / total_word_count\n",
    "            score = (0.39 * asl) + (11.8 * asw) - 15.59\n",
    "            \n",
    "            # if the sentense contains single word elements like inches then it may be too easy\n",
    "            score = max(0, score)\n",
    "        except:\n",
    "            print(f'[readability] No words found in question or answers -> {all_sentences}')\n",
    "        \n",
    "        # 0.39 x (words/sentences) + 11.8 x (syllables/words) - 15.59\n",
    "        # print(f'(0.39 * ({word_count} / {len(all_token_sets)})) + (11.8 * ({syl_count} / {word_count})) - 15.59 = {score}')\n",
    "            \n",
    "        row[COLUMN_READABILITY_FC] = score\n",
    "        \n",
    "    def __update_polysemous_count(self, row, word_tokens):\n",
    "        found_words = []\n",
    "        for word in word_tokens:\n",
    "            lemma_word = lemmatizer.lemmatize(word)\n",
    "            \n",
    "            if lemma_word in acedemic_poly_lemma:\n",
    "                found_words.append(f'({word} > {lemma_word})')\n",
    "                row[COLUMN_ACEDEMIC_POLYSEMOUS_COUNT] += 1\n",
    "                \n",
    "        row[COLUMN_ACEDEMIC_POLYSEMOUS_WORDS] = ','.join(found_words)\n",
    "    \n",
    "    # Loop through word tokens and get syllable counts\n",
    "    def __syllable_counts(self, word_tokens):\n",
    "        counts = []\n",
    "        for word in word_tokens:\n",
    "            counts.append({\n",
    "                'word': word,\n",
    "                'syllables': self.__word_syllable_count(word)\n",
    "            })\n",
    "        \n",
    "        return counts\n",
    "    \n",
    "    # Use Regex to approximate syllable count\n",
    "    # MIT License Copyright (c) 2018 Carmine M DiMascio\n",
    "    def __word_syllable_count(self, word):\n",
    "        word = word.lower()\n",
    "\n",
    "        if len(word) <= 3:\n",
    "            return 1\n",
    "\n",
    "        word = re.sub('(?:[^laeiouy]es|[^laeiouy]e)$', '', word)\n",
    "        word = re.sub('^y', '', word)\n",
    "        matches = re.findall('[aeiouy]{1,2}', word)\n",
    "        return len(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[readability] No words found in question or answers -> [' 2  /  5 + 3  /  5 + 9  /  5 + 9  /  15', '  7   /   5', '  8   /   5', '  9   /   5', '  9   /   15']\n"
     ]
    }
   ],
   "source": [
    "# Transform the DataFrame\n",
    "final_result = DataTransformer().transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to tsv since excel is dumb\n",
    "final_result.to_csv('readability_v5_04-15-2022.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1627 entries, 0 to 1626\n",
      "Data columns (total 61 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   state                       1627 non-null   object \n",
      " 1   year                        1546 non-null   float64\n",
      " 2   grade                       1627 non-null   int64  \n",
      " 3   domain                      1627 non-null   object \n",
      " 4   standard                    1437 non-null   object \n",
      " 5   pvalue                      1627 non-null   float64\n",
      " 6   hasPic                      1627 non-null   int64  \n",
      " 7   questionStem                1627 non-null   object \n",
      " 8   a                           1627 non-null   object \n",
      " 9   b                           1627 non-null   object \n",
      " 10  c                           1627 non-null   object \n",
      " 11  d                           1627 non-null   object \n",
      " 12  e                           1627 non-null   object \n",
      " 13  completeq                   1627 non-null   object \n",
      " 14  CC                          1627 non-null   int64  \n",
      " 15  CD                          1627 non-null   int64  \n",
      " 16  DT                          1627 non-null   int64  \n",
      " 17  EX                          1627 non-null   int64  \n",
      " 18  FW                          1627 non-null   int64  \n",
      " 19  IN                          1627 non-null   int64  \n",
      " 20  JJ                          1627 non-null   int64  \n",
      " 21  JJR                         1627 non-null   int64  \n",
      " 22  JJS                         1627 non-null   int64  \n",
      " 23  LS                          1627 non-null   int64  \n",
      " 24  MD                          1627 non-null   int64  \n",
      " 25  NN                          1627 non-null   int64  \n",
      " 26  NNS                         1627 non-null   int64  \n",
      " 27  NNP                         1627 non-null   int64  \n",
      " 28  NNPS                        1627 non-null   int64  \n",
      " 29  PDT                         1627 non-null   int64  \n",
      " 30  POS                         1627 non-null   int64  \n",
      " 31  PRP                         1627 non-null   int64  \n",
      " 32  PRP$                        1627 non-null   int64  \n",
      " 33  RB                          1627 non-null   int64  \n",
      " 34  RBR                         1627 non-null   int64  \n",
      " 35  RBS                         1627 non-null   int64  \n",
      " 36  RP                          1627 non-null   int64  \n",
      " 37  SYM                         1627 non-null   int64  \n",
      " 38  TO                          1627 non-null   int64  \n",
      " 39  UH                          1627 non-null   int64  \n",
      " 40  VB                          1627 non-null   int64  \n",
      " 41  VBD                         1627 non-null   int64  \n",
      " 42  VBG                         1627 non-null   int64  \n",
      " 43  VBN                         1627 non-null   int64  \n",
      " 44  VBP                         1627 non-null   int64  \n",
      " 45  VBZ                         1627 non-null   int64  \n",
      " 46  VVD                         1627 non-null   int64  \n",
      " 47  VVG                         1627 non-null   int64  \n",
      " 48  VVN                         1627 non-null   int64  \n",
      " 49  WDT                         1627 non-null   int64  \n",
      " 50  WP                          1627 non-null   int64  \n",
      " 51  WP$                         1627 non-null   int64  \n",
      " 52  WRB                         1627 non-null   int64  \n",
      " 53  $                           1627 non-null   int64  \n",
      " 54  ,                           1627 non-null   int64  \n",
      " 55  :                           1627 non-null   int64  \n",
      " 56  word_count                  1627 non-null   int64  \n",
      " 57  readability_flesch_kincaid  1627 non-null   float64\n",
      " 58  acedemic_polysemous_count   1627 non-null   int64  \n",
      " 59  acedemic_polysemous_words   1627 non-null   object \n",
      " 60  pos_tags                    1627 non-null   object \n",
      "dtypes: float64(3), int64(46), object(12)\n",
      "memory usage: 775.5+ KB\n"
     ]
    }
   ],
   "source": [
    "pos_result4.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
